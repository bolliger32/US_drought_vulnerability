### S.A.S.
### cleaning unemployment rate per county from Bureau of Labor Statistics
### 3/30

wd="~/Desktop/US_drought_vulnerability/data/unemployment/raw"
setwd(wd)

files=list.files()

unemployment=vector("list",length(files))
i=1
for(file in files){
  unemployment[[i]]=readLines(file)
  unlink(file)
  i=i+1
}

data=c()
for(i in 1:length(unemployment)){
  removeHeader=unemployment[[i]][7:length(unemployment[[i]])]
  removeTail=removeHeader[1:(length(removeHeader)-3)]
  
  splitOnWhiteSpace=lapply(removeTail,strsplit,'\\s\\s+')
  
  ## this is gross and slower than it needs to be, but for now it works
  ## make that REALLY SLOW
  for(j in 1:length(splitOnWhiteSpace)){
    data=rbind(data,splitOnWhiteSpace[[j]][[1]])
  }
  print(i)
  
}
dim(data)
data=as.data.frame(data)
names(data)=c("LAUS_CODE","state_FIPS","county_FIPS","countyState","year",
              "laborForce","employed","unemployed","unemploymentRate")

wd="~/Desktop/US_drought_vulnerability/data/unemployment"
setwd(wd)
write.csv(data,"unemploymentClean.csv",row.names=F)
## can now join on FIPS code

#test=readLines("unemployment99.txt")
#unlink("unemployment99.txt")

#strsplit(test[7],"\\s+") ## split on any number of spaces, but breaks up county names
#strsplit(test[7], '\\s\\s+') ## split on spaces > 1
