# Title: clean_county_mortality_data.py
# Inputs:
#	../data/mortality/raw/*.txt: Mortality by year/age group
# Outputs:
#	../data/mortality/mortality_cleaned.csv
#		cleaned dataset of u5 and 65+ deaths/crude death rate/age-adjusted death rate by county-year
# Authors: Ian Bolliger (bolliger@berkeley.edu)
# Date: Mar 18, 2016

### Imports
import pandas as pd
import numpy as np
from os.path import join


### filepaths
data_dir = '../data'
mort_data_dir = join(data_dir,'mortality')
raw_dir = join(mort_data_dir,'raw')

### Settings
# years, genders, ages to aggregate
years = range(1999,2015)
genders = ['b']
ages = ['65+','u5','all']

# Drop rates labeled as "unreliable"?
drop_unreliable = True

# metrics to keep
metrics = {'deaths','rate_crd','rate_adj'}


### Functions
def clean_mort_df(df, age=None, gender=None, year=None, county_col='County Code'):
    """Cleans mortality data DataFrame after it has been already loaded"""

    # Drop notes at bottom of file
    df = df[df['County Code'].notnull()]
    
    # Adjust column names
    col_dict = {
        'County Code':'county_code',
        'County':'county',
        'Deaths':'deaths_{}_{}'.format(age,gender),
        'Crude Rate':'rate_crd_{}_{}'.format(age,gender),
        'Age Adjusted Rate':'rate_adj_{}_{}'.format(age,gender)
    }
    df = df.rename(columns=col_dict)
    
    # drop metrics if don't want to include them in cleaned dataset
    to_drop = {'deaths','rate_crd','rate_adj'} - metrics
    df = df.drop(list(to_drop),axis=1)
    
    # Set county code as index
    df = df.set_index('county_code', verify_integrity=True)

    return df

def load_data(age,year,gender):
    """Load a single downloaded mortality dataset and format into appropriate DataFrame object"""
    fname = 'mort_{}_{}_{}.txt'.format(age,year,gender)
    fpath = join(raw_dir,fname)
    
    # Load data
    data = pd.read_table(fpath,
                      usecols=[2, 3, 5, 6],
                      dtype={'County Code':str},
                        na_values=['Suppressed', 'Missing'])
    
    # Drop unreliable values if desired (or keep them as numbers)
    if drop_unreliable:
        data = data.replace('.*(Unreliable)', np.nan, regex=True)
    else:
        data = data.replace('(?<=[0-9] )\(Unreliable\)', '',regex=True)
        
    # Clean data
    data = clean_mort_df(data,age=age,gender=gender)
    data = data.astype(np.float64)
    # drop if all are na
    data = data[data['deaths_{}_{}'.format(age,gender)].notnull()]
    
    # Add year to index
    data['year'] = year
    data = data.set_index('year', append=True, drop=True)
    
    # rearrange columns
    data = data.reindex(columns=
                        ['deaths_{}_{}'.format(age,gender),
                         'rate_crd_{}_{}'.format(age,gender),
                         'rate_adj_{}_{}'.format(age,gender)])
    
    return data


def clean_all(out_fname=join(mort_data_dir,'mortality_cleaned.csv'),data_dir=raw_dir):
    """Master mortality data cleaning function"""
    
    all_data = pd.DataFrame()
    for y in years:
        one_year = pd.DataFrame()
        for g in genders:
            for a in ages:
                df = load_data(a,y,g)
                if one_year.empty:
                    one_year = df
                else:
                    one_year = one_year.merge(df,left_index=True,right_index=True,how='outer')
        all_data = all_data.append(one_year, verify_integrity=False)

    # Swap county ID to "GISJOIN ID"
    all_data = all_data.reset_index()
    all_data['GISJOIN'] = 'G' + all_data['county_code'].str[:2] + '0' + all_data['county_code'].str[-3:] + '0'
    all_data = all_data.drop(['county_code'],axis=1)
    
    # sort
    all_data = all_data.set_index(['GISJOIN','year']).sort_index()
    
    # save
    all_data.to_csv(out_fname)
    
    return all_data

if __name__=='__main__':
    clean_all()
    
